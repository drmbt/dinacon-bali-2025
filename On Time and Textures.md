When I bought my first camera, I didn't know what to photograph. Pictures of people always felt forced to me, either posed and pruned, or candid, inconsequential and non-consensual. 

Landscapes are lovely, but taking a photo of another sunset or flower, while sometimes majestic, ultimately struck me as banal; I was searching for a subject that conveyed a sense of time and rhythm, that suggested a history, presented a mystery. 

I was 28 years old when with my first professional camera, a Sony A7S mkii, I found myself in Tokyo exploring the metropolis through my new camera's lens. While I certainly documented the architecture and fish markets, the bustle and sakura in bloom, I quickly found my photographic muse not in nature, society or still life, but in the textures I encountered while discovering a foreign-to-me locale. 

Textures: the concrete decay of an urban jungle, the scales of a still-bleeding tuna on ice, the irregular vertical repetition of a rusted iron grate, chipped paint and wood grain of a fence past prime; They suggest a story of man vs. nature, a chronicle of entropy as our best laid attempts at order succumb to the elements, perfect once past tense, a battle lost as indifferent environments slowly lay claim to our intents.

I must have appeared quite silly zooming in on rocks, walls, and cracks in the street amidst a sea of tourists pointing their phones at the pastel pastiche of cherry blossoms and willow trees.

Since 2015, my tradition of getting lost on such a scavenger hunt when first arriving in a new location has been going strong. I've come to enjoy quiet walks through cities and villages, forests and farmhouses, cataloguing my travel through the patterns that present themselves on these meditative meanderings whilst texture collecting. 

These images have found practical use outside of just a collection of still images, used as dirt maps and grunge layers in graphic design and VJ work, back drops in projection mapped scenic design for events and theater, and have become a special way for me to reconnect with the time and place in which I shot them. Each image evokes a personal memory, bringing me back to warehouses in Berlin, back alleys in London, the graffiti'd walls of a squat in Barcelona or an underpass in New York, affording me an intimate way to inject the unique texture of that time and place into other multi-media art works and compositions.

Since acquiring a camera, I have also uncovered a passion for timelapse photography, which scratched this itch for 4d depth that was missing from the still images I had been taking. This technique introduces a unique timescale compression to the moving image, placing each frame within a context and providing a perspective unnatural to how we normally perceive the passing of time.

As my practice evolved, I began incorporating experimental video art and VJ techniques into my traditional timelapse photography, and a method I've come to call "Time Caching" became a regular part of my workflow. This system involves a non-linear approach to displaying a "time gradient" with TouchDesigner, wherein frames from a locked off tripod shot are all loaded into video memory at once, and revealed through the luminance values of a separate, often generative video feed. This method is akin to giving each pixel in the composition its own timeline that is driven anachronistically by the brightness of a second incoming video layer, turning a "normal" linear timelapse video into a procedurally generated infinite morphing sequence, in which many or all of the frames captured can be displayed at once.

In Bali 2025 at Dinacon, my texture tradition has found a new application in a moment of inspiration as I was editing images collected from the Les village and surrounding forest. My hunch was that if I arranged the textures I'd acquired sorted by ROYGBIV (red, orange, yellow, green, blue, indigo, violet) rainbow, I might be to use the same method by which I process my time cache sequences by vibe-coding a GLSL shader that could encode the incoming hue of each pixel into the necessary luminance values to recall that color from an array of cached textures. 

With some experimentation, I realized I'd need to account for images that have a low saturation value (approximating greyscale or black and white textures), and added a method that would determine if a pixel is low saturation by calculating the distance between the values in an R G B array. If they were beneath a variable threshold, they are low saturation images and my shader would return the luminance value of each pixel mapped into the 0 - 0.5 range of the shader's output, and if its a high saturation pixel, it would be remapped in the 0.5 - 1.0 range, arranged in by ROYGBIV hue.

In this way, incoming images or videos get perceptual luminance for low saturation and hue for high saturation remapped into a single greyscale normalized video output, allowing me to, in theory, recreate any image or video with colors and hue's from a texture catalog. With 100 images (50 greyscale and 50 sorted by color) in my cache, I tested further, and got results closer to what I had imagined, but they were quite busy, and over . After some trouble shooting, I realized that I normally use a high bit depth key video for smooth results, but the inputs i was testing with were 8 bit jpegs, and their compression artifacts were causing a harshness that was undesirable.

Google helped me determine that the best method for converting an 8 bit photo to 16 bits was Topaz Gigapixel, for which I already have a license (sorry FOSS fetishists), and so I remoted into my rendering PC left in Portugal at the death-knell speed of local internet for re-processing. 

I got much better results with images upscaled to millions of colors with AI but getting a 1:1 mapping of input to output color was still a difficult challenge, as my sample set of 100 images was way too small to return the colors I actually desired from this input. With a few compositing tricks though, using multiply blend mode from the original image with my texture replacement post process and compositing trace amounts of the input over the top, I was able to attain an aesthetic that I was happy with, and create compositions that were encoded with meaning; Nature photography and process documentation from the Dinacon residency reconstituted with the decaying man made local textures I'd collected on this trip as a painterly collage, and new tool in my experimental video art journey.

I've open sourced the TouchDesigner patches I used to create this technique in this repository, and if this all doesn't sound like total gibberish jargon word salad to you (or even / especially if it does), I invite any feedback, suggestions or critique of the process. 

Post an issue, or drop an email, and thanks for taking a deeper dive into the inner workings of my process.